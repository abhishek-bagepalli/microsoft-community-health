{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30729990-4324-463d-ba37-c6b8faa35247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "ID: 1jar97x\n",
      "Title: Why Is My Model Performing So Poorly?\n",
      "Content: Hey everyone, I’m a beginner in data science, and I’m struggling with my model’s performance. Despite applying normalization, log transformation, feature selection, encoding, and everything else I can think of, my model is still performing extremely poorly.\n",
      "\n",
      "I just got an R² score of 0.06—basically no predictive power. I’m completely stuck:(\n",
      "\n",
      "For those with more experience, what are some possible reasons a model could perform this badly, even after thorough preprocessing? Any debugging tips or things I might have overlooked?\n",
      "\n",
      "Would really appreciate any insights! Me and my model thank you all in advance;)\n",
      "Author: Single-Extension728\n",
      "Subreddit: MLQuestions\n",
      "Subreddit ID: t5_30rel\n",
      "URL: https://i.redd.it/reip3l3yujoe1.jpeg\n",
      "Permalink: /r/MLQuestions/comments/1jar97x/why_is_my_model_performing_so_poorly/\n",
      "Created UTC (raw): 1741912082.0\n",
      "Created UTC (formatted): 2025-03-13 20:28:02\n",
      "Number of Comments: 8\n",
      "Score: 571\n",
      "Upvotes: 571\n",
      "Downvotes: 0\n",
      "Upvote Ratio: 0.99\n",
      "Is Self Post: False\n",
      "Link Flair Text: Beginner question 👶\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "ID: u6l4bn\n",
      "Title: How to learn Machine Learning? My Roadmap\n",
      "Content: Hello! Machine learning sparked my interest, and I'm ready to dive in. I have some previous programming knowledge but I basically start at zero in data science. So naturally, I don't really know where to begin this journey. I've researched for resources and roadmaps to learn machine learning and created my own basic roadmap just to get started.\n",
      "\n",
      "**Math - 107 hours**\n",
      "\n",
      "* [Single-Variable Calculus - MIT](https://www.youtube.com/playlist?list=PLE2215608E2574180) \\~ 29 hours\n",
      "* [Multi-Variable Calculus - MIT](https://www.youtube.com/playlist?list=PL4C4C8A7D06566F38) \\~ 29 hours\n",
      "* [Linear Algebra - MIT](https://www.youtube.com/playlist?list=PLE7DDD91010BC51F8) \\~ 28 hours\n",
      "* [Statistics & Probability - MIT](https://www.youtube.com/playlist?list=PLl8XY7QVSa4aUyZAtL2Hlf_mx3LaSix9B) \\~ 21 hours\n",
      "\n",
      "**Programming - 135 hours**\n",
      "\n",
      "* [Introduction to Computer Science and Programming Using Python](https://www.edx.org/course/introduction-to-computer-science-and-programming-7) \\~ 135 hours\n",
      "\n",
      "**Machine Learning - 200+ hours**\n",
      "\n",
      "* [Machine Learning Specialization (Andrew Ng)](https://www.deeplearning.ai/program/machine-learning-specialization/) (release June)\n",
      "* [Deep Learning Specialization (Andrew Ng)](https://www.coursera.org/learn/neural-networks-deep-learning?specialization=deep-learning&irclickid=Xa1wyCQHuzYeRMESFSRiQXN3UkGXVIyn4RCEVk0&irgwc=1) \\~ 142 hours\n",
      "\n",
      "Please give comments on it and or advice on better/more efficient ways to learn. Thanks!\n",
      "Author: Ragnuul\n",
      "Subreddit: MLQuestions\n",
      "Subreddit ID: t5_30rel\n",
      "URL: https://www.reddit.com/r/MLQuestions/comments/u6l4bn/how_to_learn_machine_learning_my_roadmap/\n",
      "Permalink: /r/MLQuestions/comments/u6l4bn/how_to_learn_machine_learning_my_roadmap/\n",
      "Created UTC (raw): 1650309604.0\n",
      "Created UTC (formatted): 2022-04-18 15:20:04\n",
      "Number of Comments: 113\n",
      "Score: 556\n",
      "Upvotes: 556\n",
      "Downvotes: 0\n",
      "Upvote Ratio: 1.0\n",
      "Is Self Post: True\n",
      "Link Flair Text: None\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "ID: 1b9jrme\n",
      "Title: Is this a overfit? What can be the solution \n",
      "Content: Hello fellow humans,\n",
      "I am working on a regression data. I am struggling to bring the MSE down but while testing most of the data is giving me minute error but there are some points which gives me prediction which are unacceptable. The metrics are \n",
      "R-square : 0.998\n",
      "MSE : 4.24\n",
      "MAE : 1.34.\n",
      "the graph attached is indicating the performance during testing.\n",
      "Author: Whole_Owl_3573\n",
      "Subreddit: MLQuestions\n",
      "Subreddit ID: t5_30rel\n",
      "URL: https://i.redd.it/u9r0w43hs2nc1.png\n",
      "Permalink: /r/MLQuestions/comments/1b9jrme/is_this_a_overfit_what_can_be_the_solution/\n",
      "Created UTC (raw): 1709888527.0\n",
      "Created UTC (formatted): 2024-03-08 04:02:07\n",
      "Number of Comments: 42\n",
      "Score: 255\n",
      "Upvotes: 255\n",
      "Downvotes: 0\n",
      "Upvote Ratio: 0.97\n",
      "Is Self Post: False\n",
      "Link Flair Text: None\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "ID: 1bnloxz\n",
      "Title: Can I call this normally distributed data? \n",
      "Content: ??\n",
      "Author: None\n",
      "Subreddit: MLQuestions\n",
      "Subreddit ID: t5_30rel\n",
      "URL: https://i.redd.it/zb1pnkl72jqc1.png\n",
      "Permalink: /r/MLQuestions/comments/1bnloxz/can_i_call_this_normally_distributed_data/\n",
      "Created UTC (raw): 1711393056.0\n",
      "Created UTC (formatted): 2024-03-25 14:57:36\n",
      "Number of Comments: 139\n",
      "Score: 237\n",
      "Upvotes: 237\n",
      "Downvotes: 0\n",
      "Upvote Ratio: 0.93\n",
      "Is Self Post: False\n",
      "Link Flair Text: None\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "ID: 1kvz801\n",
      "Title: binary classif - why am I better than the machine ?\n",
      "Content:     I have a simple binary classification task to perform, and on the picture you can see the little dataet i got. I came up with the following model of logistic regression after looking at the hyperparameters and a little optimization :\n",
      "    clf = make_pipeline(\n",
      "        StandardScaler(),\n",
      "        # StandardScaler(),\n",
      "        LogisticRegression(\n",
      "            solver='lbfgs',\n",
      "            class_weight='balanced',\n",
      "            penalty='l2',\n",
      "            C=100,\n",
      "        )\n",
      "    )\n",
      "    It gives me the predictions as depicted on the attached figure. True labels are represented with the color of each point, and the prediction of the model is represented with the color of the 2d space. I can clearly see a better line than the one found by the model. So why doesn't it converge towards the one I drew, since I am able to find it just by looking at the data ?\n",
      "Author: terrine2foie2vo\n",
      "Subreddit: MLQuestions\n",
      "Subreddit ID: t5_30rel\n",
      "URL: https://i.redd.it/titumknpn53f1.png\n",
      "Permalink: /r/MLQuestions/comments/1kvz801/binary_classif_why_am_i_better_than_the_machine/\n",
      "Created UTC (raw): 1748278182.0\n",
      "Created UTC (formatted): 2025-05-26 12:49:42\n",
      "Number of Comments: 43\n",
      "Score: 200\n",
      "Upvotes: 200\n",
      "Downvotes: 0\n",
      "Upvote Ratio: 0.97\n",
      "Is Self Post: False\n",
      "Link Flair Text: Beginner question 👶\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "ID: 1lmcoxg\n",
      "Title: What can I do to stop my RL agent from committing suicide?\n",
      "Content: I am trying to run an RL agent on multiple environments using a learned reward function. I’ve thought of zero centering it to make it „life agnostic“ but I realized that because of the fact that I’m rolling it out in all these different environments there are some environments that give it essentially all negative rewards and some that give it all positive rewards. \n",
      "So actually zero centering ended up turning my one problem into two problems. The agent now tries to commit suicide in environments it doesn’t like and stall out completing its task in one’s it does like.\n",
      "I’m sure there is social commentary in there somewhere but I’m not really interested in the philosophical implications of whether or not my rl agent would pursue a 9-5 job I just want it to try and make the most out of its situation regardless of what position it’s starting in while not aura farming everyone it interacts with.\n",
      "\n",
      "What do I do?\n",
      "Author: Guest_Of_The_Cavern\n",
      "Subreddit: MLQuestions\n",
      "Subreddit ID: t5_30rel\n",
      "URL: https://i.redd.it/4uq4qrfm4l9f1.jpeg\n",
      "Permalink: /r/MLQuestions/comments/1lmcoxg/what_can_i_do_to_stop_my_rl_agent_from_committing/\n",
      "Created UTC (raw): 1751080253.0\n",
      "Created UTC (formatted): 2025-06-27 23:10:53\n",
      "Number of Comments: 13\n",
      "Score: 155\n",
      "Upvotes: 155\n",
      "Downvotes: 0\n",
      "Upvote Ratio: 0.98\n",
      "Is Self Post: False\n",
      "Link Flair Text: Beginner question 👶\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "ID: rb3tgs\n",
      "Title: [Code Link in Comment] Understanding and working of Gradient descent\n",
      "Content: \n",
      "Author: unknown_137\n",
      "Subreddit: MLQuestions\n",
      "Subreddit ID: t5_30rel\n",
      "URL: https://v.redd.it/l1gcze4hb5481\n",
      "Permalink: /r/MLQuestions/comments/rb3tgs/code_link_in_comment_understanding_and_working_of/\n",
      "Created UTC (raw): 1638898031.0\n",
      "Created UTC (formatted): 2021-12-07 12:27:11\n",
      "Number of Comments: 14\n",
      "Score: 145\n",
      "Upvotes: 145\n",
      "Downvotes: 0\n",
      "Upvote Ratio: 0.99\n",
      "Is Self Post: False\n",
      "Link Flair Text: None\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "ID: 1ge5832\n",
      "Title: looking for a motivated friend to complete \"bulid a llm\" book\n",
      "Content: so the problem is that I had started reading this book \"Bulid a large language model from scratch\"<attached the coverpage>.\n",
      "But I find it hard to maintain consistency and I procrastinate a lot.\n",
      "I have friends but they are either not interested or enough motivated to pursue carrer in ml.\n",
      "\n",
      "So, overall I am looking for a friend so that I can become more accountable and consistent with studying ml.\n",
      "DM me if you are interested :)\n",
      "Author: meandmycrush\n",
      "Subreddit: MLQuestions\n",
      "Subreddit ID: t5_30rel\n",
      "URL: https://i.redd.it/wymqxxp5pixd1.jpeg\n",
      "Permalink: /r/MLQuestions/comments/1ge5832/looking_for_a_motivated_friend_to_complete_bulid/\n",
      "Created UTC (raw): 1730130136.0\n",
      "Created UTC (formatted): 2024-10-28 11:42:16\n",
      "Number of Comments: 75\n",
      "Score: 130\n",
      "Upvotes: 130\n",
      "Downvotes: 0\n",
      "Upvote Ratio: 0.96\n",
      "Is Self Post: False\n",
      "Link Flair Text: Other ❓\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "ID: 1if4p3t\n",
      "Title: Anyone want to learn Machine learning in a group deeply?\n",
      "Content: Hi, i'm very passionate about different sciences like neuroscience, neurology, biology, chemistry, physics and more. I think the combination of ML along with different areas in those topics is very powerful and has a lot of potential. Would anyone be interested in joining a group to collaborate on certain research related to these subjects combined with ML or even to learn ML and Math more deeply. Thanks.\n",
      "\n",
      "  \n",
      "Edit - Here is the link - [https://discord.gg/H5R38UWzxZ](https://discord.gg/H5R38UWzxZ)\n",
      "Author: Rais244522\n",
      "Subreddit: MLQuestions\n",
      "Subreddit ID: t5_30rel\n",
      "URL: https://www.reddit.com/r/MLQuestions/comments/1if4p3t/anyone_want_to_learn_machine_learning_in_a_group/\n",
      "Permalink: /r/MLQuestions/comments/1if4p3t/anyone_want_to_learn_machine_learning_in_a_group/\n",
      "Created UTC (raw): 1738410605.0\n",
      "Created UTC (formatted): 2025-02-01 06:50:05\n",
      "Number of Comments: 89\n",
      "Score: 120\n",
      "Upvotes: 120\n",
      "Downvotes: 0\n",
      "Upvote Ratio: 0.96\n",
      "Is Self Post: True\n",
      "Link Flair Text: Beginner question 👶\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "ID: wmn3xw\n",
      "Title: I've recorded over 1500 farts to train a model to recognize farts. Who or how do I share the dataset with to be more available to anyone who may find it useful for audio tasks?\n",
      "Content: I've collected over 1500 fart audio files in the .wav format. I'll be collecting many more as time goes on. I'm building a mobile app for fun that does something on a \"wake sound,\" similar to how Alexa and Google Home do something on a \"wake word.\" I'd love to make my fart dataset available to anyone who may find it useful for audio tasks. Who or how would I reach out to do this?\n",
      "\n",
      "&#x200B;\n",
      "\n",
      "Edit: dataset available here - [https://www.kaggle.com/datasets/alecledoux/fart-recordings-dataset](https://www.kaggle.com/datasets/alecledoux/fart-recordings-dataset)\n",
      "Author: JerryAttricked\n",
      "Subreddit: MLQuestions\n",
      "Subreddit ID: t5_30rel\n",
      "URL: https://www.reddit.com/r/MLQuestions/comments/wmn3xw/ive_recorded_over_1500_farts_to_train_a_model_to/\n",
      "Permalink: /r/MLQuestions/comments/wmn3xw/ive_recorded_over_1500_farts_to_train_a_model_to/\n",
      "Created UTC (raw): 1660315695.0\n",
      "Created UTC (formatted): 2022-08-12 10:48:15\n",
      "Number of Comments: 31\n",
      "Score: 105\n",
      "Upvotes: 105\n",
      "Downvotes: 0\n",
      "Upvote Ratio: 0.95\n",
      "Is Self Post: True\n",
      "Link Flair Text: None\n",
      "----------------------------------------\n",
      "\n",
      "✅ Data saved to data\\reddit_metrics_MLQuestions_20250708_164159.xlsx\n",
      "✅ Top comments saved to data\\reddit_comments_MLQuestions_20250708_164159.xlsx\n",
      "\n",
      "📈 Summary Statistics:\n",
      "Total Posts Analyzed: 10\n",
      "Average Upvotes: 247.40\n",
      "Average Comments: 56.70\n",
      "Posts with Links: 7\n",
      "Posts Removed by Mods: 0\n",
      "AMA Posts: 0\n",
      "\n",
      "📅 Timestamp Analysis:\n",
      "Number of unique timestamps: 10\n",
      "\n",
      "First few timestamps:\n",
      "0   2025-03-13 20:28:02\n",
      "1   2022-04-18 15:20:04\n",
      "2   2024-03-08 04:02:07\n",
      "3   2024-03-25 14:57:36\n",
      "4   2025-05-26 12:49:42\n",
      "Name: created_utc, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Authenticate\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"\",\n",
    "    client_secret=\"\",\n",
    "    user_agent=\"script:fetcher:v1.0 (by u/YOUR_USERNAME)\"\n",
    ")\n",
    "\n",
    "# Choose a subreddit\n",
    "subreddit = reddit.subreddit(\"MLQuestions\")\n",
    "\n",
    "# Initialize counters\n",
    "ama_count = 0\n",
    "post_count = 0\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "data_dir = 'data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "# Create Excel filenames\n",
    "timestamp_str = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "excel_filename = os.path.join(data_dir, f\"reddit_metrics_{subreddit.display_name}_{timestamp_str}.xlsx\")\n",
    "comments_filename = os.path.join(data_dir, f\"reddit_comments_{subreddit.display_name}_{timestamp_str}.xlsx\")\n",
    "\n",
    "# Create Excel writer for posts\n",
    "with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:\n",
    "    columns = ['id', 'title', 'content', 'author', 'subreddit', 'subreddit_id', 'url', \n",
    "              'permalink', 'created_utc', 'num_comments', 'score', 'upvotes', 'downvotes',\n",
    "              'upvote_ratio', 'is_self', 'link_flair_text', 'has_link', 'removed_by_mods']\n",
    "    pd.DataFrame(columns=columns).to_excel(writer, index=False)\n",
    "\n",
    "# Create Excel writer for comments\n",
    "with pd.ExcelWriter(comments_filename, engine='openpyxl') as writer:\n",
    "    comment_columns = [\n",
    "        'post_id', 'comment_id', 'comment_author', 'comment_body', 'comment_score', 'comment_created_utc', 'comment_permalink'\n",
    "    ]\n",
    "    pd.DataFrame(columns=comment_columns).to_excel(writer, index=False)\n",
    "\n",
    "# Helper function to get the next available row in an Excel sheet\n",
    "def get_next_row(filename, sheet_name=0):\n",
    "    if not os.path.exists(filename):\n",
    "        return 1  # Only header exists\n",
    "    try:\n",
    "        df = pd.read_excel(filename, sheet_name=sheet_name)\n",
    "        return len(df) + 1  # +1 for header\n",
    "    except Exception:\n",
    "        return 1\n",
    "\n",
    "# Fetch top 10 hot posts\n",
    "for post in subreddit.top(limit=10):\n",
    "    # Generate random timeout between 10 and 30 seconds\n",
    "    timeout = random.randint(10, 30)\n",
    "    time.sleep(timeout)\n",
    "    \n",
    "    # Convert UTC timestamp to datetime\n",
    "    created_utc = datetime.fromtimestamp(post.created_utc)\n",
    "    \n",
    "    # Print post details\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"ID: {post.id}\")\n",
    "    print(f\"Title: {post.title}\")\n",
    "    print(f\"Content: {post.selftext}\")\n",
    "    print(f\"Author: {post.author}\")\n",
    "    print(f\"Subreddit: {post.subreddit}\")\n",
    "    print(f\"Subreddit ID: {post.subreddit_id}\")\n",
    "    print(f\"URL: {post.url}\")\n",
    "    print(f\"Permalink: {post.permalink}\")\n",
    "    print(f\"Created UTC (raw): {post.created_utc}\")\n",
    "    print(f\"Created UTC (formatted): {created_utc}\")\n",
    "    print(f\"Number of Comments: {post.num_comments}\")\n",
    "    print(f\"Score: {post.score}\")\n",
    "    print(f\"Upvotes: {post.ups}\")\n",
    "    print(f\"Downvotes: {post.downs}\")\n",
    "    print(f\"Upvote Ratio: {post.upvote_ratio}\")\n",
    "    print(f\"Is Self Post: {post.is_self}\")\n",
    "    print(f\"Link Flair Text: {post.link_flair_text}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Create single post DataFrame\n",
    "    post_df = pd.DataFrame([{\n",
    "        'id': post.id,\n",
    "        'title': post.title,\n",
    "        'content': post.selftext,\n",
    "        'author': str(post.author),\n",
    "        'subreddit': str(post.subreddit),\n",
    "        'subreddit_id': post.subreddit_id,\n",
    "        'url': post.url,\n",
    "        'permalink': post.permalink,\n",
    "        'created_utc': created_utc,  # Store the datetime object instead of raw timestamp\n",
    "        'num_comments': post.num_comments,\n",
    "        'score': post.score,\n",
    "        'upvotes': post.ups,\n",
    "        'downvotes': post.downs,\n",
    "        'upvote_ratio': post.upvote_ratio,\n",
    "        'is_self': post.is_self,\n",
    "        'link_flair_text': post.link_flair_text,\n",
    "        'has_link': bool(post.url) and not post.is_self,\n",
    "        'removed_by_mods': post.removed_by_category == \"moderator\"\n",
    "    }])\n",
    "    \n",
    "    # Append to Excel file at the correct row\n",
    "    post_startrow = get_next_row(excel_filename)\n",
    "    with pd.ExcelWriter(excel_filename, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "        post_df.to_excel(writer, index=False, header=False, startrow=post_startrow)\n",
    "    \n",
    "    post_count += 1\n",
    "    \n",
    "    # Count AMA posts\n",
    "    if post.link_flair_text and 'AMA' in post.link_flair_text.upper():\n",
    "        ama_count += 1\n",
    "\n",
    "    # --- Fetch top 5 comments for this post ---\n",
    "    post.comments.replace_more(limit=0)\n",
    "    top_comments = []\n",
    "    for i, comment in enumerate(post.comments[:5]):\n",
    "        if isinstance(comment, praw.models.Comment):\n",
    "            comment_created_utc = datetime.fromtimestamp(comment.created_utc)\n",
    "            comment_permalink = f\"https://www.reddit.com{comment.permalink}\"\n",
    "            top_comments.append({\n",
    "                'post_id': post.id,\n",
    "                'comment_id': comment.id,\n",
    "                'comment_author': str(comment.author),\n",
    "                'comment_body': comment.body,\n",
    "                'comment_score': comment.score,\n",
    "                'comment_created_utc': comment_created_utc,\n",
    "                'comment_permalink': comment_permalink\n",
    "            })\n",
    "    if top_comments:\n",
    "        comments_df = pd.DataFrame(top_comments)\n",
    "        comments_startrow = get_next_row(comments_filename)\n",
    "        with pd.ExcelWriter(comments_filename, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "            comments_df.to_excel(writer, index=False, header=False, startrow=comments_startrow)\n",
    "\n",
    "print(f\"\\n✅ Data saved to {excel_filename}\")\n",
    "print(f\"✅ Top comments saved to {comments_filename}\")\n",
    "\n",
    "# Read the final Excel file to get summary statistics\n",
    "df = pd.read_excel(excel_filename)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n📈 Summary Statistics:\")\n",
    "print(f\"Total Posts Analyzed: {post_count}\")\n",
    "print(f\"Average Upvotes: {df['upvotes'].mean():.2f}\")\n",
    "print(f\"Average Comments: {df['num_comments'].mean():.2f}\")\n",
    "print(f\"Posts with Links: {df['has_link'].sum()}\")\n",
    "print(f\"Posts Removed by Mods: {df['removed_by_mods'].sum()}\")\n",
    "print(f\"AMA Posts: {ama_count}\")\n",
    "\n",
    "# Print unique timestamps to verify\n",
    "print(\"\\n📅 Timestamp Analysis:\")\n",
    "print(f\"Number of unique timestamps: {df['created_utc'].nunique()}\")\n",
    "print(\"\\nFirst few timestamps:\")\n",
    "print(df['created_utc'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a73340b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ms-scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
